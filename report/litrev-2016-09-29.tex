\section{Accelerator Design for Graph Analytics}
This paper \cite{ozdal2016energy} is essentially a graph accelerator implementation framework of Gather-Apply-Scatter model as in GraphLab \cite{nurvitadhi2014graphgen}. It particularly focuses on iterative graph-parallel applications with asynchronous
execution and asymmetric convergence. In order to support domain of graph processing, it has a
template of hardware for common operations including memory access, synchronization and
communication. In order to provide application specific optimization, a design space exploration is
also supported like typical domain specific accelerators.

\subsection{Highlights}
Here are the list of highlights of this work.
\begin{itemize}
    \item It targets graph applications with asynchronous execution and asymmetric convergence which
        doesn't work well on GPUs. This is also one of the major reasons that contributes to the the high power efficiency.
    \item It provides a hardware version of GraphLab \cite{nurvitadhi2014graphgen} and maintains sequential consistency model with a synchronous unit (SYU) which essentially follows the edge consistency. 
    \item memory access optimization: It has special cache, load, store units for each data type such as vertex information (VI) and edge information (EI). The cache structure is also configurable to meet the requirements of as VI and EI which have different locality characteristic. 
    \item Graph partition: The framework has each accelerator optimized for fine grained operation level parallelism. And it also replicates the accelerator unit to explore high-level parallelism based on a static graph partition.
\end{itemize}

\subsection{Questions}
Is it necessary to maintain sequential consistency, will it be possible to loose the consistency model for more parallelism and higher performance?

According to the Graphicionado \cite{hamgra2016phicionado}, cache may not be a good memory hierarchy for graph processing as the graph problems typically has poor locality. Will a scratch pad memory work better for this design? This work utilize vertex and edge as the basic cache granularity instead of general data type may probably alleviate the problem.

The graph partition is not detailed, how does the partition affect the overall system performance? 


\section{Graphicioando}
This paper utilize GraphMat \cite{sundaram2015graphmat} as the graph processing framework. With the observation that graph processing has ineffective usage of both on-chip memory and bandwidth, this work particularly optimizes the on chip memory usage over the baseline hardware accelerator obtained from GraphMat. 

According to the pipeline of the baseline accelerator, the on chip memory access characteristics of the different pipeline stages are analyzed and a few optimizations are applied to remove the bottleneck of the accelerator pipeline. Here are the list of the major optimizations.
\begin{itemize}
    \item It uses on-chip eDRAM as scratchpad memory to alleviate the random destination vertex and edge ID access. For the rest of the sequential memory access, a prefetch scheme is used to hide the memory access latency,
    \item Instead of replicating the accelerator directly, the authors divide the processing phase into source oriented portion and destination oriented portion. With this strategy, the hardware can be easily partitioned into parts without overlaps. Basically, the scratchpad memory is shared among the vertex processing streams. 
    \item The number of edges are typically much larger than that of the vertex, so the edge access is usually a bottleneck of the accelerator design. This work uses an array of input queues and output queues connected with a crossbar to access memory and feed data to the downstream processing. 
    \item In order to cope with graphs with larger scratchpad memory requirements, the graph is sliced, though the slicing is a simple one.
\end{itemize}

\section{Database query with hardware/software co-design}
This work is supposed to handle OLTP, but it doesn't show any special design for OLTP system.

